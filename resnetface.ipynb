{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet 18 on faces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 75\n",
    "rate = 0.15\n",
    "epochs = 150\n",
    "lr_decay = 0.84\n",
    "lr_stride = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, transform, train=True):\n",
    "        self.image_prefix = \"face_renders/face\"\n",
    "        self.image_suffix = \".jpg\"\n",
    "        self.vertex_prefix = \"processed_faces/face\"\n",
    "        self.vertex_suffix = \".txt\"\n",
    "        self.count = 5000\n",
    "        self.trainn = 4500\n",
    "        \n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        \n",
    "        shape = np.loadtxt(self.vertex_prefix + str(1) + self.vertex_suffix).shape\n",
    "        tmp = np.zeros((self.count, shape[0], shape[1]))\n",
    "        for i in range(self.count):\n",
    "            tmp[i] = np.loadtxt(self.vertex_prefix + str(i + 1) + self.vertex_suffix)\n",
    "            \n",
    "        self.mean = np.mean(tmp, axis=0)\n",
    "        self.outputdim = shape[0] * shape[1]\n",
    "        self.labels = [torch.from_numpy((lab - self.mean).reshape(self.outputdim)).float() for lab in tmp]\n",
    "        \n",
    "        self.images = [plt.imread(self.image_prefix + str(i + 1) + self.image_suffix) for i in range(self.count)]\n",
    "            \n",
    "        # simple version for working with CWD\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return self.trainn\n",
    "        else:\n",
    "            return self.count - self.trainn\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.train:\n",
    "            idx += self.trainn\n",
    "        return (self.transform(self.images[idx]), self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = FaceDataset(transform, train=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchsize,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = FaceDataset(transform, train=False)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize,\n",
    "                                          shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available()   = True\n",
      "torch.cuda.device_count()   = 1\n",
      "torch.cuda.device('cuda')   = <torch.cuda.device object at 0x000001CBBBB565F8>\n",
      "torch.cuda.current_device() = 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"torch.cuda.is_available()   =\", torch.cuda.is_available())\n",
    "print(\"torch.cuda.device_count()   =\", torch.cuda.device_count())\n",
    "print(\"torch.cuda.device('cuda')   =\", torch.cuda.device(0))\n",
    "print(\"torch.cuda.current_device() =\", torch.cuda.current_device())\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "trainloader = DeviceDataLoader(trainloader, device)\n",
    "testloader = DeviceDataLoader(testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet.resnet101(output_size=trainset.outputdim)\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=rate)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, decay, stride):\n",
    "    lr = rate * (decay ** (epoch // stride))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, epochs, trainloader, testloader):\n",
    "    model.train()\n",
    "    samples = 1\n",
    "    losses = []\n",
    "#     test_losses = []\n",
    "    k = len(trainloader)// samples\n",
    "    \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % k == k - 1:\n",
    "\n",
    "                losses.append(running_loss / k)\n",
    "                \n",
    "#                 testloss = 0\n",
    "#                 total = 0\n",
    "#                 iterations = 0\n",
    "#                 with torch.no_grad():\n",
    "#                     for data in testloader:\n",
    "#                         images, labels = data\n",
    "#                         outputs = model(images)\n",
    "#                         testloss += criterion(outputs, labels)\n",
    "#                         total += labels.size(0)\n",
    "#                         iterations += 1\n",
    "#                         if total > 200:\n",
    "#                             break\n",
    "#                 test_losses.append(testloss / iterations)\n",
    "                \n",
    "                print('[%d, %5d] loss: %.3f test_loss: %.3f' %(epoch + 1, i + 1,losses[-1], 0)) #test_losses[-1]\n",
    "\n",
    "                running_loss = 0.0\n",
    "                \n",
    "        adjust_learning_rate(optimizer, epoch+1, lr_decay, lr_stride)\n",
    "\n",
    "    print('Finished Training')\n",
    "    plt.plot(np.arange(0, len(losses)/samples, 1.0/samples), losses)\n",
    "    plt.title(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.show()\n",
    "    \n",
    "#     plt.plot(np.arange(0, len(test_losses)/samples, 1.0/samples), test_losses)\n",
    "#     plt.title(\"test_loss\")\n",
    "#     plt.xlabel(\"epoch\")\n",
    "#     plt.ylabel(\"test_losses\")\n",
    "#     plt.show()\n",
    "    model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    60] loss: 9.569 test_loss: 0.000\n",
      "[2,    60] loss: 7.261 test_loss: 0.000\n",
      "[3,    60] loss: 5.850 test_loss: 0.000\n",
      "[4,    60] loss: 5.102 test_loss: 0.000\n",
      "[5,    60] loss: 4.678 test_loss: 0.000\n",
      "[6,    60] loss: 4.331 test_loss: 0.000\n",
      "[7,    60] loss: 4.106 test_loss: 0.000\n",
      "[8,    60] loss: 3.800 test_loss: 0.000\n",
      "[9,    60] loss: 3.597 test_loss: 0.000\n",
      "[10,    60] loss: 3.415 test_loss: 0.000\n",
      "[11,    60] loss: 3.188 test_loss: 0.000\n",
      "[12,    60] loss: 3.043 test_loss: 0.000\n",
      "[13,    60] loss: 2.940 test_loss: 0.000\n",
      "[14,    60] loss: 2.839 test_loss: 0.000\n",
      "[15,    60] loss: 2.765 test_loss: 0.000\n",
      "[16,    60] loss: 2.592 test_loss: 0.000\n",
      "[17,    60] loss: 2.475 test_loss: 0.000\n",
      "[18,    60] loss: 2.401 test_loss: 0.000\n",
      "[19,    60] loss: 2.340 test_loss: 0.000\n",
      "[20,    60] loss: 2.290 test_loss: 0.000\n",
      "[21,    60] loss: 2.206 test_loss: 0.000\n",
      "[22,    60] loss: 2.147 test_loss: 0.000\n",
      "[23,    60] loss: 2.116 test_loss: 0.000\n",
      "[24,    60] loss: 2.048 test_loss: 0.000\n",
      "[25,    60] loss: 2.009 test_loss: 0.000\n",
      "[26,    60] loss: 1.952 test_loss: 0.000\n",
      "[27,    60] loss: 1.921 test_loss: 0.000\n",
      "[28,    60] loss: 1.910 test_loss: 0.000\n",
      "[29,    60] loss: 1.864 test_loss: 0.000\n",
      "[30,    60] loss: 1.826 test_loss: 0.000\n",
      "[31,    60] loss: 1.789 test_loss: 0.000\n",
      "[32,    60] loss: 1.736 test_loss: 0.000\n",
      "[33,    60] loss: 1.724 test_loss: 0.000\n",
      "[34,    60] loss: 1.711 test_loss: 0.000\n",
      "[35,    60] loss: 1.653 test_loss: 0.000\n",
      "[36,    60] loss: 1.618 test_loss: 0.000\n",
      "[37,    60] loss: 1.576 test_loss: 0.000\n",
      "[38,    60] loss: 1.570 test_loss: 0.000\n",
      "[39,    60] loss: 1.547 test_loss: 0.000\n",
      "[40,    60] loss: 1.541 test_loss: 0.000\n",
      "[41,    60] loss: 1.499 test_loss: 0.000\n",
      "[42,    60] loss: 1.490 test_loss: 0.000\n",
      "[43,    60] loss: 1.468 test_loss: 0.000\n",
      "[44,    60] loss: 1.452 test_loss: 0.000\n",
      "[45,    60] loss: 1.436 test_loss: 0.000\n",
      "[46,    60] loss: 1.417 test_loss: 0.000\n",
      "[47,    60] loss: 1.398 test_loss: 0.000\n",
      "[48,    60] loss: 1.377 test_loss: 0.000\n",
      "[49,    60] loss: 1.381 test_loss: 0.000\n",
      "[50,    60] loss: 1.354 test_loss: 0.000\n",
      "[51,    60] loss: 1.345 test_loss: 0.000\n",
      "[52,    60] loss: 1.330 test_loss: 0.000\n",
      "[53,    60] loss: 1.340 test_loss: 0.000\n",
      "[54,    60] loss: 1.307 test_loss: 0.000\n",
      "[55,    60] loss: 1.311 test_loss: 0.000\n",
      "[56,    60] loss: 1.284 test_loss: 0.000\n",
      "[57,    60] loss: 1.285 test_loss: 0.000\n",
      "[58,    60] loss: 1.277 test_loss: 0.000\n",
      "[59,    60] loss: 1.258 test_loss: 0.000\n",
      "[60,    60] loss: 1.261 test_loss: 0.000\n",
      "[61,    60] loss: 1.242 test_loss: 0.000\n",
      "[62,    60] loss: 1.230 test_loss: 0.000\n",
      "[63,    60] loss: 1.238 test_loss: 0.000\n",
      "[64,    60] loss: 1.210 test_loss: 0.000\n",
      "[65,    60] loss: 1.220 test_loss: 0.000\n",
      "[66,    60] loss: 1.221 test_loss: 0.000\n",
      "[67,    60] loss: 1.205 test_loss: 0.000\n",
      "[68,    60] loss: 1.199 test_loss: 0.000\n",
      "[69,    60] loss: 1.201 test_loss: 0.000\n",
      "[70,    60] loss: 1.169 test_loss: 0.000\n",
      "[71,    60] loss: 1.179 test_loss: 0.000\n",
      "[72,    60] loss: 1.162 test_loss: 0.000\n",
      "[73,    60] loss: 1.170 test_loss: 0.000\n",
      "[74,    60] loss: 1.162 test_loss: 0.000\n",
      "[75,    60] loss: 1.152 test_loss: 0.000\n",
      "[76,    60] loss: 1.141 test_loss: 0.000\n",
      "[77,    60] loss: 1.146 test_loss: 0.000\n",
      "[78,    60] loss: 1.131 test_loss: 0.000\n",
      "[79,    60] loss: 1.133 test_loss: 0.000\n",
      "[80,    60] loss: 1.154 test_loss: 0.000\n",
      "[81,    60] loss: 1.128 test_loss: 0.000\n",
      "[82,    60] loss: 1.126 test_loss: 0.000\n",
      "[83,    60] loss: 1.124 test_loss: 0.000\n",
      "[84,    60] loss: 1.135 test_loss: 0.000\n",
      "[85,    60] loss: 1.114 test_loss: 0.000\n",
      "[86,    60] loss: 1.105 test_loss: 0.000\n",
      "[87,    60] loss: 1.131 test_loss: 0.000\n",
      "[88,    60] loss: 1.110 test_loss: 0.000\n",
      "[89,    60] loss: 1.121 test_loss: 0.000\n",
      "[90,    60] loss: 1.106 test_loss: 0.000\n",
      "[91,    60] loss: 1.108 test_loss: 0.000\n",
      "[92,    60] loss: 1.092 test_loss: 0.000\n",
      "[93,    60] loss: 1.111 test_loss: 0.000\n",
      "[94,    60] loss: 1.099 test_loss: 0.000\n",
      "[95,    60] loss: 1.097 test_loss: 0.000\n",
      "[96,    60] loss: 1.093 test_loss: 0.000\n",
      "[97,    60] loss: 1.113 test_loss: 0.000\n",
      "[98,    60] loss: 1.084 test_loss: 0.000\n",
      "[99,    60] loss: 1.073 test_loss: 0.000\n",
      "[100,    60] loss: 1.088 test_loss: 0.000\n",
      "[101,    60] loss: 1.067 test_loss: 0.000\n",
      "[102,    60] loss: 1.069 test_loss: 0.000\n",
      "[103,    60] loss: 1.074 test_loss: 0.000\n",
      "[104,    60] loss: 1.089 test_loss: 0.000\n",
      "[105,    60] loss: 1.072 test_loss: 0.000\n",
      "[106,    60] loss: 1.087 test_loss: 0.000\n",
      "[107,    60] loss: 1.060 test_loss: 0.000\n",
      "[108,    60] loss: 1.073 test_loss: 0.000\n",
      "[109,    60] loss: 1.066 test_loss: 0.000\n",
      "[110,    60] loss: 1.065 test_loss: 0.000\n",
      "[111,    60] loss: 1.063 test_loss: 0.000\n",
      "[112,    60] loss: 1.074 test_loss: 0.000\n",
      "[113,    60] loss: 1.067 test_loss: 0.000\n",
      "[114,    60] loss: 1.064 test_loss: 0.000\n",
      "[115,    60] loss: 1.085 test_loss: 0.000\n",
      "[116,    60] loss: 1.079 test_loss: 0.000\n",
      "[117,    60] loss: 1.060 test_loss: 0.000\n",
      "[118,    60] loss: 1.080 test_loss: 0.000\n",
      "[119,    60] loss: 1.056 test_loss: 0.000\n",
      "[120,    60] loss: 1.070 test_loss: 0.000\n",
      "[121,    60] loss: 1.056 test_loss: 0.000\n",
      "[122,    60] loss: 1.062 test_loss: 0.000\n",
      "[123,    60] loss: 1.072 test_loss: 0.000\n",
      "[124,    60] loss: 1.043 test_loss: 0.000\n",
      "[125,    60] loss: 1.039 test_loss: 0.000\n",
      "[126,    60] loss: 1.054 test_loss: 0.000\n",
      "[127,    60] loss: 1.059 test_loss: 0.000\n",
      "[128,    60] loss: 1.050 test_loss: 0.000\n",
      "[129,    60] loss: 1.045 test_loss: 0.000\n",
      "[130,    60] loss: 1.048 test_loss: 0.000\n",
      "[131,    60] loss: 1.046 test_loss: 0.000\n",
      "[132,    60] loss: 1.049 test_loss: 0.000\n",
      "[133,    60] loss: 1.045 test_loss: 0.000\n",
      "[134,    60] loss: 1.056 test_loss: 0.000\n",
      "[135,    60] loss: 1.056 test_loss: 0.000\n",
      "[136,    60] loss: 1.041 test_loss: 0.000\n",
      "[137,    60] loss: 1.052 test_loss: 0.000\n",
      "[138,    60] loss: 1.066 test_loss: 0.000\n",
      "[139,    60] loss: 1.050 test_loss: 0.000\n",
      "[140,    60] loss: 1.039 test_loss: 0.000\n",
      "[141,    60] loss: 1.042 test_loss: 0.000\n",
      "[142,    60] loss: 1.052 test_loss: 0.000\n",
      "[143,    60] loss: 1.054 test_loss: 0.000\n",
      "[144,    60] loss: 1.050 test_loss: 0.000\n",
      "[145,    60] loss: 1.047 test_loss: 0.000\n",
      "[146,    60] loss: 1.036 test_loss: 0.000\n",
      "[147,    60] loss: 1.046 test_loss: 0.000\n",
      "[148,    60] loss: 1.035 test_loss: 0.000\n",
      "[149,    60] loss: 1.041 test_loss: 0.000\n",
      "[150,    60] loss: 1.048 test_loss: 0.000\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(model, optimizer, criterion, epochs, trainloader, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"res101b\" + str(batchsize) + \"r\" + str(rate) + \"e\" + str(epochs) + \".statedict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-57.42849171  43.50585649  81.09827847]\n",
      " [-57.10330025  40.76217867  80.77729131]\n",
      " [-56.4013172   36.99098729  79.87123442]\n",
      " ...\n",
      " [ 54.11570628 -43.99206555  66.38817782]\n",
      " [ 55.6071899  -46.20434955  60.50756982]\n",
      " [ 56.74632444 -47.9137754   53.69290953]]\n",
      "tensor([-2.2968, -2.0359,  5.6980,  ...,  7.2326, -1.8773,  1.3138], device='cuda:0')\n",
      "tensor([-2.9954, -1.1436,  5.3742,  ...,  6.9024, -1.8781,  1.2504], device='cuda:0')\n",
      "48.44615\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    d = next(testloader.__iter__())\n",
    "    images, labels = d\n",
    "    outputs = model(images)\n",
    "    \n",
    "    print(trainset.mean)\n",
    "    print(outputs[0])\n",
    "    print(labels[0])\n",
    "    print(np.linalg.norm((labels[0] - outputs[0]).to('cpu').numpy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.std([l.numpy() for l in trainset.labels], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1692, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = resnet.resnet101(output_size=trainset.outputdim)\n",
    "model.load_state_dict(torch.load(\"res101b75r0.15e150.statedict\"))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712.0628659248353\n"
     ]
    }
   ],
   "source": [
    "running_loss = 0\n",
    "criterion = nn.MSELoss()\n",
    "start = 4501\n",
    "for i, data in enumerate(testloader, 0):\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    for o in outputs:\n",
    "        arr = o.detach().to(\"cpu\").numpy().reshape((564,3)) + testset.mean\n",
    "        \n",
    "        np.savetxt(\"predictions/face\" + str(start) + \".txt\", arr, fmt=\"%.9f\")\n",
    "        start += 1\n",
    "    \n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    \n",
    "print(running_loss / 500 * 75 * 564)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "print (len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
